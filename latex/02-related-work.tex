\section{Related Work}
This section discusses previous studies related to deep-learning based in medical imaging, and the use of GAN-generated data for medical data augmentation. Limitations of existing approaches are discussed to position the contributions of this work.

\subsection{GAN-based Augmentation in Medical Imaging}
Generative Adversarial Networks (GANs)~\cite{goodfellow2014gan} and CycleGAN~\cite{zhu2017cyclegan} are widely used for medical image synthesis and augmentation. Empirical evidence shows substantial gains in CT-based classification and segmentation when augmenting with GAN-generated images~\cite{frid2018gan,sandfort2019cycleganCT}. However, transferring these benefits to spatially sensitive object detection is less clear. CycleGAN-based augmentation for YOLO in multi-organ CT detection reported mixed outcomes~\cite{hammami2020cyclegan}, suggesting that appearance-level transformations may not consistently enhance bounding-box localization. \\
Beyond GANs, diffusion models and style-based generators provide additional context. Transformer- and latent-diffusion approaches improve anatomical consistency and downstream performance in multiple modalities~\cite{pan2023ddpm,khader2023ddpm3d}. 3D and StyleGAN-based methods have modeled lung CT textures with high realism~\cite{ellis2022stylegan3d,shi2020stylegan}. These works indicate that volumetric or anatomy-aware synthesis may be more suitable than purely appearance-level augmentation for tasks requiring precise localization.

\subsection{Object Detection in Chest CT}
In chest CT object detection, LUNA16 is a common benchmark dataset used with AP/mAP and IoU metrics; detection models such as Faster R-CNN, RetinaNet, and the YOLO familiy serve as typical baselines~\cite{setio2017luna16,padilla2020metrics,redmon2016yolo,ren2015fasterrcnn,lin2017focal,ragab2024yoloreview}. \\
Recent CT-specific works demonstrate strong baselines via multi-scale receptive fields, transfer learning, and data-centric tuning~\cite{wu2024yolomsrf,harsono2022retinanet,nguyen2022datacentric,wehbe2024yolov8}. \\
However, the focus of this work remains on a comparison of appearance-level augmentations versus CycleGAN-based augmentation for CT object detection, using LUNA16 as a benchmark dataset and YOLO11 as the baseline detection model.

\subsection{Positioning of This Work}
Prior literature establishes the utility of GAN augmentation primarily for classification and segmentation~\cite{frid2018gan,sandfort2019cycleganCT}, while evidence for CT-based object detection remains limited and inconclusive~\cite{hammami2020cyclegan}. This paper addresses that gap through a controlled comparison of four training settings (baseline, classical augmentation, baseline + CycleGAN, classical augmentation + CycleGAN) under identical hyperparameters and evaluation metrics (AP@0.5, AP@0.5:0.95, Mean IoU). Our findings provide insights into the limitations of CycleGAN-based augmentation for medical object detection.
